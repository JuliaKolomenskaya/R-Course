---
title: "HW 2: From correlation to linear mixed-effect models. Assignment sheet"
---

```{r setup, include=FALSE}
library(tidyverse)
library(lme4)
library(vcd)
```

## 1. Vowel reduction in Russian
Pavel Duryagin ran an experiment on perception of vowel reduction in Russian language. The dataset `shva` includes the following variables:  
_time1_ - reaction time 1  
_duration_ - duration of the vowel in the stimuly (in milliseconds, ms)  
_time2_ - reaction time 2  
_f1_, _f2_, _f3_ - the 1st, 2nd and 3rd formant of the vowel measured in Hz (for a short introduction into formants, see [here](https://home.cc.umanitoba.ca/~krussll/phonetics/acoustic/formants.html))  
_vowel_ - vowel classified according the 3-fold classification (_A_ - _a_ under stress, _a_ - _a/o_ as in the first syllable before the stressed one, _y_ (stands for shva) - _a/o_ as in the second etc. syllable before the stressed one or after the stressed syllable, cf. _g_[_y_]_g_[_a_]_t_[_A_]_l_[_y_] _gogotala_ `guffawed').  
In this part, we will ask you to analyse correlation between f1, f2, and duration.
The dataset is available [https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/duryagin_ReductionRussian.txt](here).

### 1.0 Read the data from file to the variable `shva`.
```{r 1.0}
shva=read.csv("https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/duryagin_ReductionRussian.txt",sep="\t")
```

### 1.1 Scatterplot _f1_ and _f2_ 
using ggplot(). Design it to look like the <a href="https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/img/duryagin1.png">following</a>.
```{r 1.1}
ggplot(data=shva,aes(f2,f1,fill=vowel)) + geom_point(aes(color=vowel))+ggtitle("f2 and f1 of the reduced and stressed vowels")+scale_y_reverse()+scale_x_reverse()
```

### 1.2 Plot the boxplots of _f1_ and _f2_ for each vowel using `ggplot()`. Design it to look like the <a href="https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/img/duryagin2.png">following</a>.
```{r 1.2}
# f1 boxplot
shva %>% ggplot(aes(vowel,f1,fill=vowel))+geom_boxplot()+coord_flip()+ggtitle("f1 distribution in each vowel")
# f2 boxplot
shva %>% ggplot(aes(vowel,f2,fill=vowel))+geom_boxplot()+coord_flip()+ggtitle("f2 distribution in each vowel")
```

### 1.3 Which _f1_ can be considered outliers in _a_ vowel?
We assume outliers to be those observations that lie outside 1.5 * IQR, where IQR, the 'Inter Quartile Range', is the difference between the 1st and the 3rd quartile (= 25% and 75% percentile).
```{r 1.3}
shva$f1[(shva$f1<quantile(shva$f1,1/4)-1.5*IQR(shva$f1))|(shva$f1>quantile(shva$f1,3/4)+1.5*IQR(shva$f1))]
#As we can see, there are no outliers in the data
```

### 1.4 Calculate Pearson's correlation of f1 and f2 (all data)
```{r 1.4}
cor(shva$f1,shva$f2,method="pearson")
```

### 1.5 Calculate Pearson's correlation of f1 and f2 for each vowel
```{r 1.5}
cor(shva$f1[shva$vowel=="A"],shva$f2[shva$vowel=="A"],method="pearson")
cor(shva$f1[shva$vowel=="a"],shva$f2[shva$vowel=="a"],method="pearson")
cor(shva$f1[shva$vowel=="y"],shva$f2[shva$vowel=="y"],method="pearson")

```

### 1.6 Use the linear regression model to predict f2 by f1.
```{r 1.6} 
fit=lm(f1~f2,data=shva)
```
### 1.6.1 Provide the result regression formula
```{r 1.6.1}
print(fit)
#The final regression formula: f1=1678.9408-0.7839 *f2
```

### 1.6.2 Provide the adjusted R2
```{r 1.6.2}
summary(fit)
#The adjusted R-squared equals to 0.3319 
```

### 1.6.3 Add the regression line in scatterplot 1.1
```{r 1.6.3}
shva$model=predict(fit)
ggplot(data=shva,aes(f2,f1,fill=vowel)) + geom_point(aes(color=vowel))+ggtitle("f2 and f1 of the reduced and stressed vowels")+geom_line(aes(f2,model))+scale_y_reverse()+scale_x_reverse()+ theme_gray(base_size = 14)
```

### 1.7 Use the mixed-efects model to predict f2 by f1 using vowel intercept as a random effect
```{r 1.7}
fit2=lmer(f1~f2 + (1 | vowel), data =shva)
```

### 1.7.1 Provide the fixed effects formula
```{r 1.7.1}
summary(fit2)
#The fixed effects formula is:
#f1=489.32283+0.06269*f2
```

### 1.7.2 Provide the variance for intercept argument for vowel random effects
```{r 1.7.2}
#16741
```

### 1.7.3 Add the regression line in scatterplot 1.1
```{r 1.7.3}
shva$model2=predict(fit2)
ggplot(data=shva,aes(f2,f1,fill=vowel)) + geom_point(aes(color=vowel))+ggtitle("f2 and f1 of the reduced and stressed vowels")+geom_line(aes(f2,model2,color=vowel))+scale_y_reverse()+scale_x_reverse()+ theme_gray(base_size = 14)
``` 

## 2. English Lexicon Project data
880 nouns, adjectives and verbs from the English Lexicon Project data (Balota et al. 2007).

* Format -- A data frame with 880 observations on the following 5 variables.
* Word -- a factor with lexical stimuli.
* Length -- a numeric vector with word lengths.
* SUBTLWF -- a numeric vector with frequencies in film subtitles.
* POS -- a factor with levels JJ (adjective) NN (noun) VB (verb)
* Mean_RT -- a numeric vector with mean reaction times in a lexical decision task
Source (http://elexicon.wustl.edu/WordStart.asp)

Data from Natalya Levshina's `RLing` package available (here)[https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/ELP.csv]

### 2.0 Read the data from file to the variable `elp`.
```{r 2.0}
elp=read.csv("https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/ELP.csv")
```

### 2.1 Which two variables have the highest Pearson's correlaton value?
```{r 2.1}
cor(elp[c(2,3,5)],method="spearman")
#The highest positive correlation can be observed between Length and Mean_RT,the highest negative correlation-between SUBTLWF and Mean_RT.
```

### 2.2 Group your data by parts of speech and make a scatterplot of SUBTLWF and Mean_RT.
```{r 2.2}
new=elp %>% group_by("POS")
theme_set(theme_light())
new %>%
ggplot(aes(SUBTLWF,Mean_RT))+geom_point(aes(color=Length))+scale_color_continuous(low = "lightblue", high = "red")+facet_wrap(~POS) + scale_x_log10()
```

We've used `scale_color_continuous(low = "lightblue", high = "red")` as a parameter of ggplot().

### 2.3 Use the linear regression model to predict Mean_RT by log(SUBTLWF) and POS.
#### 2.3.1 Provide the result regression formula
```{r 2.3.1}
fit3=lm(new$Mean_RT~log(new$SUBTLWF),new$POS)
summary(fit3)
#The formula is: Mean_RT=769.112-38.211*log(SUBTLWF) 
```

#### 2.3.2 Provide the adjusted R$^2$
```{r 2.3.2}
#Adjusted R-squared:  0.3271
```

#### 2.3.3 Add the regression line in the scatterplot.
```{r 2.3.3}
new$model=predict(fit3)
new %>% ggplot(aes(log(SUBTLWF),Mean_RT))+geom_point(aes(log(SUBTLWF),Mean_RT,color=Length))+geom_line(aes(log(SUBTLWF),model))+scale_color_continuous(low = "lightblue", high = "red")
```

### 2.4 Use the mixed-efects model to predict f2 by f1 using POS intercept as a random effect
#### 2.4.1 Provide the fixed effects formula
```{r 2.4.1}
lmer(Mean_RT~log(SUBTLWF) + (1 | POS), data = new)
#The formula is:Mean_RT=767.71-37.67*log(SUBTLWF)
```

#### 2.4.2 Provide the variance for intercept argument for POS random effects
```{r 2.4.2}
summary(lmer(Mean_RT~log(SUBTLWF) + (1 | POS), data = new))
#The variance is 414.4
```

#### 2.4.3 Add the regression line to the scatterplot
```{r 2.4.3}
fit4=lmer(Mean_RT~log(SUBTLWF) + (1 | POS), data = new)
new$model2=predict(fit4)
new %>% ggplot(aes(log(SUBTLWF),Mean_RT))+geom_point(aes(color=POS))+geom_line(aes(log(SUBTLWF),model2))+facet_wrap(~POS)+ theme_gray(base_size = 14)+theme(legend.position="none")
```

## 3. Dutch causative constructions

This is a data set with examples of two Dutch periphrastic causatives extracted from newspaper corpora.

The data frame includes 100 observations on the following 7 variables:

* Cx -- a factor with levels doen_V and laten_V
* CrSem -- a factor that contains the semantic class of the Causer with levels Anim (animate) and Inanim (inanimate).
* CeSem -- a factor that describes the semantic class of the Causee with levels Anim (animate) and Inanim (inanimate).
* CdEv -- a factor that describes the semantic domain of the caused event expressed by the Effected Predicate. The levels are Ment (mental), Phys (physical) and Soc (social).
* Neg -- a factor with levels No (absence of negation) and Yes (presence of negation).
* Coref -- a factor with levels No (no coreferentiality) and Yes (coreferentiality).
* Poss -- a factor with levels No (no overt expression of possession) Yes (overt expression of possession)

Data from Natalya Levshina's `RLing` package available (here)[https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/dutch_causatives.csv]

### 3.0 Read the data from file to the variable `d_caus`.
```{r 3.0}
d_caus=read.csv("https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/dutch_causatives.csv")
```

### 3.1 We are going to test whether the association between `Aux` and other categorical variables (`Aux` ~ `CrSem`, `Aux` ~ `CeSem`, etc) is statistically significant. The association with which variable should be analysed using Fisher's Exact Test and not using Pearson's Chi-squared Test? Is this association statistically significant?
```{r 3.1}
#CeSem
#No, it is not.
```

### 3.2. Test the hypothesis that `Aux` and `EPTrans` are not independent with the help of Pearson's Chi-squared Test. 
```{r 3.2}
X=chisq.test(d_caus$Aux,d_caus$EPTrans)
X
#Since p-value is less, than .05, the null hypothesis is rejected, thus Aux and EPTrans are dependent.
```

### 3.3 Provide expected values for Pearson's Chi-squared Test of `Aux` and `EPTrans` variables.
```{r 3.3}
X$expected
```

### 3.4. Calculate the odds ratio.
```{r 3.4}
fisher.test(d_caus$Aux,d_caus$EPTrans)
fisher.test(d_caus$Aux,d_caus$CrSem)
fisher.test(d_caus$Aux,d_caus$CeSem)
fisher.test(d_caus$Aux,d_caus$CdEvSem)
fisher.test(d_caus$Aux,d_caus$CeSynt)
fisher.test(d_caus$Aux,d_caus$Country)
fisher.test(d_caus$Aux,d_caus$Domain)
```

### 3.5 Calculate effect size for this test using Cramer's V (phi).
```{r 3.5}
q=d_caus[c("Aux","EPTrans")]
V=sqrt(14.307/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","CrSem")]
V=sqrt(244.2/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","CeSem")]
V=sqrt(3.336/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","CdEvSem")]
V=sqrt(18.057/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","CeSynt")]
V=sqrt(71.663/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","Country")]
V=sqrt(14.911/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V

q=d_caus[c("Aux","Domain")]
V=sqrt(29.22/(nrow(q)*ncol(q)*(min(nrow(q),ncol(q))-1)))
V
```

### 3.6. Report the results of independence test using the following template:
```
We have found a significant association between variables Aux and all the variables, except CeSem (p < 0.001).  The odds of the independence were 2-11 times higher / lower in (group Aux|CeSem) than in (other groups). Effect size is large (Cramer's V = 0.494166).
```

### 3.7 Visualize the distribution using mosaic plot.
Use `mosaic()` function from `vcd` library.
```{r 3.7}
vcd::mosaic(~ Aux+CeSem+EPTrans, data=d_caus, shade=TRUE, legend=TRUE)
```

Below is an example of how to use mosaic() with three variables.
```{r 3.7.1}
# mosaic(~ Aux + CrSem + Country, data=d_caus, shade=TRUE, legend=TRUE)
```

### 3.8 Why is it not recommended to run multiple Chisq tests of independence on different variables within your dataset whithout adjusting for the multiplicity? (i.e. just testing all the pairs of variables one by one)  
```
#It may result in incorrect p-values.
```

### 3.9 Provide a short text (300 words) describing the hypothesis on this study and the results of your analysis.
```{r 3.9}
#The research under consideration is aimed at investigating the independce/dependence of two Dutch periphrastic causatives from various factors, ranging from Country to semantic classes of Causer and Causee. The initial(null) hypothesis is that there's no dependence between these causatives and the aforementioned factors. In order to confirm our hypothesis, we performed Chi-squared test for each pair of variables(one of them being the type of the causative), calculated the odds ratios and calculated the effect size for the test we conducted. 
#The analysis performed here shows, that most of the factors are statistically significant, thus, we reject null hypotheses about the independence between the causatives and these factors. Throughout the research, we discovered, that only the semantic class of Causee is not a statistically significant factor, which is supported by big p-value acquiqred during our test.
#To conclude, our statistical analysis reveals a dependence between the use of the 2 Dutch causatives under consideration and the factors related to Geography, the domain, where the causatives are used, syntactic features, semantic class of the Causer and semantic class of the caused event.
```

